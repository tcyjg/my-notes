# 思维导图

![[NotebookLM Mind Map.png]]

![[Pasted image 20260123092627.png]]


从终端中进入redis：redis-cli   [Optional]

# redis的数据结构：

# redis 的线程模型
单线程
Redis 6.0 版本之后，Redis 在启动的时候，默认情况下会**额外创建 6 个线程**
- Redis-server ： Redis的主线程，主要负责执行命令；
- bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF刷盘任务、释放内存任务；
- io_thd_1、io_thd_2、io_thd_3：三个 I/O 线程，io-threads 默认是 4 ，所以会启动 3（4-1）个 I/O 多线程，用来分担 Redis 网络 I/O 的压力。

## [#](https://xiaolincoding.com/redis/base/redis_interview.html#redis-%E6%8C%81%E4%B9%85%E5%8C%96)Redis 持久化

### 一、核心基础数据结构（最常用）

这是 Redis 最核心、最基础的 5 种数据结构，覆盖 90% 以上的日常使用场景。
#### 1. String（字符串）

- **用途**：最基础的结构，存储文本、数字（整数/浮点数）、二进制数据（如图片、序列化对象），比如存储用户昵称、商品价格、验证码、计数器等。
    
- **特点**：单个 String 最大支持 512MB，支持按字符串、数字两种方式操作。
    
- **基础操作**：
    
    ```Bash
    # 设置值（key: name, value: zhangsan）
    SET name zhangsan
    # 获取值
    GET name  # 返回 "zhangsan"
    # 数字自增（计数器场景）
    SET count 0
    INCR count  # count 变为 1
    INCRBY count 5  # count 变为 6
    # 设置过期时间（比如验证码 5 分钟过期）
    SET code 123456 EX 300
    ```
    

#### 2. Hash（哈希）

- **用途**：存储结构化数据，比如用户信息（id、姓名、年龄、手机号）、商品信息（id、名称、价格），相当于 Redis 中的“微型数据库行”。
    
- **特点**：一个 Hash 可以包含多个键值对（field-value），操作时可以针对单个 field 增删改查，无需修改整个结构。
    
- **基础操作**：
    
    ```Bash
    # 设置用户信息（key: user:1001，field: name/age，value: 张三/25）
    HSET user:1001 name 张三 age 25
    # 获取单个 field 的值
    HGET user:1001 name  # 返回 "张三"
    # 获取所有 field 和 value
    HGETALL user:1001  # 返回 ["name","张三","age","25"]
    # 修改单个 field
    HSET user:1001 age 26
    # 删除单个 field
    HDEL user:1001 age
    ```
    

#### 3. List（列表）

- **用途**：有序、可重复的集合，适合实现队列（FIFO）、栈（LIFO）、最新消息列表，比如订单排队、朋友圈动态、评论列表。
    
- **特点**：基于双向链表实现，头部/尾部增删元素效率极高（O(1)），中间增删效率低（O(n)）。
    
- **基础操作**：
    
    ```Bash
    # 从列表尾部添加元素（队列：左进右出）
    LPUSH msg "hello"  # 列表: ["hello"]
    LPUSH msg "world"  # 列表: ["world", "hello"]
    # 从列表尾部弹出元素
    RPOP msg  # 返回 "hello"，列表剩余 ["world"]
    # 获取列表指定范围元素
    LRANGE msg 0 -1  # 返回 ["world"]（0 是第一个，-1 是最后一个）
    ```
    

#### 4. Set（集合）

- **用途**：无序、唯一的集合，适合去重、交集/并集/差集运算，比如用户标签、抽奖名单、共同好友。
    
- **特点**：元素不可重复，支持集合间的数学运算（核心优势）。
    
- **基础操作**：
    
    ```Bash
    # 添加元素（key: tag:user:1001，标签：篮球、音乐）
    SADD tag:user:1001 篮球 音乐 旅游
    # 判断元素是否存在
    SISMEMBER tag:user:1001 篮球  # 返回 1（存在）
    # 获取集合所有元素
    SMEMBERS tag:user:1001  # 返回 ["篮球","音乐","旅游"]
    # 求两个集合的交集（共同好友）
    SADD friend:1001 1002 1003 1004
    SADD friend:1002 1003 1005
    SINTER friend:1001 friend:1002  # 返回 ["1003"]
    ```
    

#### 5. Sorted Set（有序集合）

- **用途**：有序、唯一的集合，每个元素关联一个分数（score），按分数排序，适合排行榜（如销量榜、积分榜）、延时任务。
    
- **特点**：元素唯一，但分数可重复；排序是核心，支持按分数范围、排名范围查询。
    
- **基础操作**：
    
    ```Bash
    # 添加元素（key: rank:sales，元素：商品1/2/3，分数：销量）
    ZADD rank:sales 100 商品1 200 商品2 150 商品3
    # 按分数升序获取所有元素（WITHSCORES 显示分数）
    ZRANGE rank:sales 0 -1 WITHSCORES  # 返回 ["商品1",100,"商品3",150,"商品2",200]
    # 按分数降序获取前2名（销量榜Top2）
    ZREVRANGE rank:sales 0 1 WITHSCORES  # 返回 ["商品2",200,"商品3",150]
    # 获取元素的排名（降序）
    ZREVRANK rank:sales 商品2  # 返回 0（排名从0开始，第1名）
    ```

##### **跳表的使用**
redis中的sorted Set是使用ziplist（listpack）和 skiplist
skiplist 基于多层有序链表的数据结构，用于在**有序集合**中实现**高效的查找、插入和删除**操作，时间复杂度接近于平衡树
更新时，当前每个层级的前一个节点的backward指针会进行更新（是否建立层级），是随机建立的。

### 二、高级数据结构（针对性场景）

这些结构是基于基础结构扩展的，解决特定业务问题，实用性也很高。
#### 1. Bitmap（位图）

- **用途**：按位存储数据，适合海量二进制状态记录，比如用户签到、活跃用户统计、是否已读。
    
- **特点**：极大节省空间（1 字节=8 位，存储 8 个状态），支持位运算（与/或/异或）。
    
- **示例（用户签到）**：
    
    ```Bash
    # 用户1001在第1天、第3天签到（位索引从0开始）
    SETBIT sign:1001 0 1  # 第1天签到（索引0）
    SETBIT sign:1001 2 1  # 第3天签到（索引2）
    # 查看第1天是否签到
    GETBIT sign:1001 0  # 返回 1
    # 统计签到天数
    BITCOUNT sign:1001  # 返回 2
    ```
    

#### 2. HyperLogLog（基数统计）

- **用途**：统计海量数据的**不重复数量**（基数），比如日活用户数、页面UV，无需存储具体数据。
    
- **特点**：占用空间极小（固定 12KB），精度约 0.81% 误差，适合“无需精确值、只求大致数量”的场景。
    
- **示例（统计UV）**：
    
    ```Bash
    # 记录访问页面A的用户
    PFADD uv:pageA 1001 1002 1003 1001  # 重复的1001会被去重
    # 统计UV数量
    PFCOUNT uv:pageA  # 返回 3
    # 合并多个页面的UV（比如统计全站UV）
    PFADD uv:pageB 1003 1004 1005
    PFMERGE uv:total uv:pageA uv:pageB
    PFCOUNT uv:total  # 返回 5
    ```
    

#### 3. Geo（地理空间）

- **用途**：存储地理位置（经纬度），支持距离计算、附近位置查询，比如外卖商家推荐、打车附近司机。
    
- **示例（附近商家）**：
    
    ```Bash
    # 添加商家位置（key: shop，商家ID：shop1，纬度：39.908823，经度：116.397470）
    GEOADD shop 116.397470 39.908823 shop1
    GEOADD shop 116.407470 39.918823 shop2
    # 查询shop1到shop2的距离（单位：米）
    GEODIST shop shop1 shop2 m  # 返回约 1500 米（具体值以实际计算为准）
    # 查询指定位置附近的商家（半径1公里，按距离排序）
    GEORADIUS shop 116.397470 39.908823 1000 m WITHDIST
    ```
    

### 总结

1. 基础结构：String（单值）、Hash（结构化）、List（有序可重）、Set（无序唯一）、Sorted Set（有序唯一），覆盖绝大多数常规场景。
    
2. 高级结构：Bitmap（二进制状态）、HyperLogLog（基数统计）、Geo（地理空间），解决特定场景的性能/空间问题。
    
3. 核心原则：选数据结构的关键是**匹配业务场景**（比如去重用Set、排行榜用Sorted Set、统计UV用HyperLogLog），而非强行用某一种。






# redis的持久化
Redis 共有三种数据持久化的方式：
- **AOF 日志**：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；
- **RDB 快照**：将某一时刻的内存数据，以二进制的方式写入磁盘；
- **混合持久化方式**：Redis 4.0 新增的方式，集成了 AOF 和 RDB 的优点；

## AOF (append only file)
AOF（Append Only File）：AOF 持久化记录服务器接收到的每个写入操作，这些操作将在服务器启动时再次被执行，重建原始数据集。
（先执行写命令，再写入日志文件）。
Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。 在 Redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数可填：

- **Always**，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；
- **Everysec**，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；
- **No**，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。

这种持久性的方法能够确保比 RDB 快照更持久，因为它是一个仅附加文件。随着操作的发生，我们将它们缓冲到日志中，但它们还没有被持久化。
Redis写入AOF日志文件
1. Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区；
2. 然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；
3. 具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。

## RDB(redis 数据库)
RDB（Redis 数据库）：RDB 持久化以指定的时间间隔执行数据集的时间点快照。

这种机制的主要缺点是快照之间的数据会丢失。此外，这种存储机制还依赖于主进程的 fork，在更大的数据集中，这可能会导致服务请求的瞬间延迟。但是加载时间比AOF快得多

## Frok操作
Forking 是操作系统通过创建自身副本来创建新进程的一种方式。这样，你将获得一个新的进程 ID 和一些其他信息和句柄，因此新 forking 的进程（子进程）可以与原始进程父进程通信。

当你 fork 一个进程时，父进程和子进程共享内存，并且在该子进程中 Redis 开始**快照（Redis）** 进程。这是通过一种称为**写时复制**的内存共享技术实现的——该技术在创建分叉时传递对内存的引用。
1. 如果在子进程持久化到磁盘时没有发生任何更改，则不会进行新的分配。
2. 在发生更改的情况下，内核会跟踪对每个页面的引用，如果某个页面有多个更改，则将更改写入新页面。子进程完全不知道更改以及具有一致的内存快照的事情。因此，在只使用了一小部分内存的情况下，我们能够非常快速有效地获得潜在千兆字节内存的时间点快照！



# redis的架构
<ul style="color: #0000ff; line-height: 1.6; font-size: 18px; list-style-type: disc; padding-left: 20px; margin: 0;"> <li>Redis 复制用于数据同步和读扩展，但不具备自动故障转移能力；</li> <li>Redis 哨兵在主从复制基础上提供监控和自动选主，实现高可用；</li> <li>Redis 集群通过 Hash 槽进行数据分片，支持写扩展，并内建高可用机制，适合大规模高并发场景。</li> </ul>

## 1.1 Redis 复制
将一个 Redis 实例（主节点，Master）的数据，实时或准实时地同步到一个或多个 Redis 实例（从节点，Replica/Slave） 的机制.
**Redis 复制的核心目标：**
1. **数据冗余（高可用）**  
    主节点宕机后，从节点可以顶替，减少数据丢失风险。
2. **读写分离（性能扩展）**
    - 主节点：处理写请求
    - 从节点：处理读请求  
        减轻主节点压力。
3. **灾备与数据恢复**  
    从节点保留主节点的完整副本，可用于备份或快速恢复。

## 1.2 Redis 哨兵
在主从复制基础上，提供sentinel监控、自动故障转移和通知，可以监控主从服务器，并且提供**主从节点故障转移的功能。**

当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 **Redis 切片集群**。它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。

Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，**一个切片集群共有 16384 个哈希槽**，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：

- 根据键值对的 key，按照 [CRC16 算法 (opens new window)](https://en.wikipedia.org/wiki/Cyclic_redundancy_check)计算一个 16 bit 的值。
- 再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

接下来的问题就是，这些哈希槽怎么被映射到具体的 Redis 节点上的呢？有两种方案：

- **平均分配：** 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。
- **手动分配：** 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。

当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 **Redis 切片集群**
## 1.3 redis 集群
**数据分片**
## 1.4 实现高可用的原理(主从复制)：
**主从复制**是 Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式。

主服务器可以进行**读写**操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是**只读**，并接受主服务器同步过来写操作命令，然后执行这条命令。

主从服务器间的复制是异步的，当写操作写在主服务器中时，就会马上返回，之后发给从服务器进行写时，异步操作，会导致一致性有一定影响

[主从复制是怎么实现的？ | 小林coding | Java面试学习](https://xiaolincoding.com/redis/cluster/master_slave_replication.html#%E6%80%BB%E7%BB%93)
主从复制共有三种模式：**全量复制、基于长连接的命令传播、增量复制**。

主从服务器第一次同步的时候，就是采用全量复制，此时主服务器会两个耗时的地方，分别是生成 RDB 文件和传输 RDB 文件。为了避免过多的从服务器和主服务器进行全量复制，可以把一部分从服务器升级为「经理角色」，让它也有自己的从服务器，通过这样可以分摊主服务器的压力。

第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。

如果遇到网络断开，增量复制就可以上场了，不过这个还跟 repl_backlog_size 这个大小有关系。

如果它配置的过小，主从服务器网络恢复时，可能发生「从服务器」想读的数据已经被覆盖了，那么这时就会导致主服务器采用全量复制的方式。所以为了避免这种情况的频繁发生，要调大这个参数的值，以降低主从服务器断开后全量同步的概率。







# redis过期淘汰和内存删除
Redis 会把该 key 带上过期时间存储到一个**过期字典**（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。

当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：

- 如果不在，则正常读取键值；
- 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。
### 过期删除策略
#### redis中处理方式
**惰性删除：**
不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。
**定期删除：**
每隔一段时间「随机」从数据库中**随机**取出一定数量的 key 进行检查，并删除其中的过期key。
 **Redis 选择「惰性删除+定期删除」这两种策略配和使用**，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。
 ---
#### redis持久化时，过期键的处理
Redis 持久化文件有两种格式：RDB（Redis Database）和 AOF（Append Only File），下面我们分别来看过期键在这两种格式中的呈现状态。

RDB 文件分为两个阶段，RDB 文件生成阶段和加载阶段。

- **RDB 文件生成阶段**：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，**过期的键「不会」被保存到新的 RDB 文件中**，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。
- **RDB 加载阶段**：RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况：
    - **如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中**。所以过期键不会对载入 RDB 文件的主服务器造成影响；
    - **如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中**。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响。

AOF 文件分为两个阶段，AOF 文件写入阶段和 AOF 重写阶段。

- **AOF 文件写入阶段**：当 Redis 以 AOF 模式持久化时，**如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值**。
- **AOF 重写阶段**：执行 AOF 重写时，会对 Redis 中的键值对进行检查，**已过期的键不会被保存到重写后的 AOF 文件中**，因此不会对 AOF 重写造成任何影响。
---

#### 主从模式中，键过期
从服务器不会检测key是否过期，如果如果过期，仍然正常返回。

从库的过期键处理依靠主服务器控制，**主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库**，从库通过执行这条 del 指令来删除过期的 key。

---
## 内存淘汰机制
**LRU** 全称是 Least Recently Used 翻译为**最近最少使用**，会选择淘汰最近最少使用的数据。
Redis 实现的是一种**近似 LRU 算法**，目的是为了更好的节约内存，它的**实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间**。
Redis 实现的 **LRU 算法**的优点：

- 不用为所有的数据维护一个大链表，节省了空间占用；
- 不用在每次数据访问时都移动链表项，提升了缓存的性能；

但是 LRU 算法有一个问题，**无法解决缓存污染问题**，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染
**引入LFU解决问题**
LFU 全称是 Least Frequently Used 翻译为**最近最不常用的**，LFU 算法是根据数据访问次数来淘汰数据的。



当 Redis 进行内存淘汰时，会使用**随机采样的方式来淘汰数据**，它是随机取 5 个值（此值可配置），然后**淘汰最久没有使用的那个**。

# redis缓存设计
 三种策略
- Cache Aside（旁路缓存）策略；
- Read/Write Through（读穿 / 写穿）策略；
- Write Back（写回）策略；

### 1. Cache Aside（旁路缓存） 
策略是最常用的，应用程序直接与「数据库、缓存」交互，并负责对缓存的维护，该策略又可以细分为「读策略」和「写策略」。
 **写策略的步骤：**
- 先更新数据库中的数据，再删除缓存中的数据。
**读策略的步骤：**
- 如果读取的数据命中了缓存，则直接返回数据；
- 如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。

注意，写策略的步骤的顺序不能倒过来，即**不能先删除缓存再更新数据库**，原因是在「读+写」并发的时候，会出现缓存和数据库的数据不一致性的问题。


### _**2、Read Through 策略**_

先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库查询数据，并将结果写入到缓存组件，最后缓存组件将数据返回给应用。

### _**3、Write Through 策略**_

当有数据更新的时候，先查询要写入的数据在缓存中是否已经存在：

- 如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。
- 如果缓存中数据不存在，直接更新数据库，然后返回；


# redis的实战应用

# Question
####  1. 缓存雪崩
**情况**：redis服务崩溃，缓存失效，导致大量请求打到数据库,导致数据库宕机或者系统不可用。
**原因** 缓存集中失效，例如大量缓存设置了相同的过期时间。 缓存服务器宕机，所有缓存数据瞬间不可用。

**解决方案** 
- 设置缓存过期时间随机化，避免大量缓存同时失效。 
- 在系统上线前进行缓存预热，提前加载热点数据。
- 使用多级缓存架构，将热点数据部分存储在本地缓存中。
- 部署高可用的缓存集群，例如使用 Redis Cluster 或哨兵模式。
#### 2. 缓存穿透
**情况**：请求数据不存在数据库中，导致请求多次访问数据库，导致缓存穿透
**原因** 恶意攻击或爬虫构造大量不存在的请求。 业务逻辑导致查询不存在的数据。

**解决方案** 
- 缓存空结果，将查询不到的数据缓存为 null，并设置较短的过期时间。
- 使用布隆过滤器拦截不存在的请求，避免直接访问数据库。
- 对请求参数进行严格校验，过滤非法请求。
#### 3. 缓存击穿
**情况**：一个热点的key，突然失效，导致此时所有请求都会访问数据库。
**原因** 热点数据的缓存过期时间到达，且没有及时更新缓存。

**解决方案** 
- 对热点数据设置永不过期，并通过定时任务更新缓存。
- 使用互斥锁机制，确保同一时刻只有一个线程能更新缓存。
- 采用逻辑过期策略，返回旧值的同时异步更新缓存。


#### 4. redis中异步删除时，会不会读到脏数据
Redis 的异步删除并不会影响数据一致性。  
因为 Redis 在主线程中先完成 key 的逻辑删除，使其立即对后续查询不可见；  
后台线程只负责对象的物理内存释放，不参与读写路径。  
再加上 Redis 命令执行是单线程的，因此不会出现读到旧数据或脏数据的问题。

### 5. 集群脑裂导致数据丢失怎么办
先来理解集群的脑裂现象，这就好比一个人有两个大脑，那么到底受谁控制呢？

> [!解释]
> 
> 那么在 Redis 中，集群脑裂产生数据丢失的现象是怎样的呢？
> 
> 在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。 如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。
> 
> 这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在「从节点」中选举出一个 leader 作为主节点，这时集群就有两个主节点了 —— **脑裂出现了**。
> 
> 然后，网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，**因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题**。
> 
> 总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。

**解决方案**
当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。

在 Redis 的配置文件中有两个参数我们可以设置：

- min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。
- min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。

我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。

这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的写请求了。

即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，**原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了**。

**等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。**